
import pickle
import os.path
import csv

from Token import Token

TOKEN_FILE  = "tokens.dat"
PARSER_FILE = "include/parser.h"

# Special lexer tokens that should NOT generate a warning
no_lexer_only_warn = ["*"]

# Special lexer tokens that should NOT warn about being a hexadecimal number
no_lexer_hex_warn = ["D"]

# Function only to read the token data
def read_tokens():
    with open(TOKEN_FILE, "rb") as token_file:
        return pickle.load(token_file)
    return tokens

def save_tokens(tokens):
    with open(TOKEN_FILE, "wb") as token_file:
        pickle.dump(tokens, token_file)

def get_max_value(tokens):
    max_value = -1
    for token in tokens:
        if token.id > max_value:
            max_value = token.id
    return max_value

def read_parser_tokens():
    parser_tokens = dict()
    with open(PARSER_FILE, "r") as token_file:
        reader = csv.reader(token_file, delimiter=' ', quotechar='|')
        for row in reader:
            # We are only interested in the second item (macro name) and the last item (id)
            parser_tokens[row[1]] = int(row[-1])
    return parser_tokens

def add(token):
    if os.path.isfile(TOKEN_FILE):
        tokens = read_tokens()
    else:
        tokens = set() # Adding to a set prevents duplicate macro names
    tokens.add(token)
    save_tokens(tokens)

def update_values():
    # list of Tokens
    lexer_tokens = read_tokens()
    # dict of macro:id
    parser_tokens = read_parser_tokens()
    
    for mname in parser_tokens:
        parser_only = True
        for token in lexer_tokens:
            if token.macro_name == mname:
                parser_only = False
        if parser_only:
            print "*** Warning:\ttoken %s is only defined by the PARSER!" % mname
    
    # 1. First get the values from the parser
    for token in lexer_tokens:
        try:
            # Update the id to the value generated by the parser
            token.id = parser_tokens[token.macro_name]
        except KeyError as e:
            # This token is only defined by the lexer
            if token.plain_text not in no_lexer_only_warn:
                print "*** Warning:\ttoken %s is only defined by the LEXER!" % token.plain_text
            token.id = -1
    # 2. Create new values for lexer only tokens
    for token in lexer_tokens:
        try:
            hex = int(token.plain_text, 16)
            if token.plain_text not in no_lexer_hex_warn:
                print "*** Warning:\ttoken %s is valid hexadecimal number!" % token.plain_text
        except ValueError as e:
            pass
        if token.id < 0:
            token.id = get_max_value(lexer_tokens) + 1
    # 3. Save for later
    save_tokens(lexer_tokens)